# üéØ GNSS Model Accuracy Improvement Guide

## Current Performance Summary

### Short-term (15min-1h): ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- Average RMSE: ~0.10m
- Use for: Real-time corrections

### Medium-term (2h-6h): ‚≠ê‚≠ê‚≠ê Good
- Average RMSE: ~0.35m
- Use for: Planning

### Long-term (12h-24h): ‚≠ê‚≠ê Fair
- Average RMSE: ~0.70m
- Needs improvement

---

## üöÄ 10 Ways to Increase Accuracy

### 1. **More Training Data** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Highest Impact)

**Current:** ~600 samples (4 days)  
**Recommended:** 2000+ samples (2+ weeks)

**Why it helps:**
- More patterns for model to learn
- Better generalization
- Reduced overfitting

**How to implement:**
```python
# Collect more GNSS data files
# Place in data/raw/
# Run cleaning and feature engineering
python clean_dataset.py
python feature_engineering.py
python train_models_improved.py
```

**Expected improvement:** +20-30% accuracy

---

### 2. **Improved Hyperparameters** ‚≠ê‚≠ê‚≠ê‚≠ê (High Impact)

**I've created `train_models_improved.py` with:**

#### LightGBM Improvements:
```python
'learning_rate': 0.03,        # Slower, more stable (was 0.05)
'max_depth': 8,               # Prevent overfitting (was -1)
'min_child_samples': 20,      # Require more samples per leaf
'reg_alpha': 0.1,             # L1 regularization (NEW)
'reg_lambda': 0.1,            # L2 regularization (NEW)
'num_boost_round': 3000,      # More rounds with early stopping
```

#### LSTM Improvements:
```python
'hidden_size': 128,           # More capacity (was 64)
'num_layers': 3,              # Deeper (was 2)
'dropout': 0.3,               # More regularization (was 0.2)
'learning_rate': 0.0005,      # Slower convergence (was 0.001)
'lookback': 96,               # 24 hours context (was 48)
'patience': 15,               # Early stopping (NEW)
```

**Expected improvement:** +10-15% accuracy

---

### 3. **Early Stopping** ‚≠ê‚≠ê‚≠ê‚≠ê (High Impact)

**Problem:** Current LSTM overfits after epoch 7
- Training loss: 0.279
- Validation loss: 0.772 (increases after epoch 7)

**Solution:** Implemented in improved script
```python
# Stops training when validation loss stops improving
patience = 15  # Wait 15 epochs before stopping
```

**Expected improvement:** +15-20% for long-term predictions

---

### 4. **Longer Lookback Window** ‚≠ê‚≠ê‚≠ê‚≠ê (High Impact)

**Current:** 48 timesteps (12 hours)  
**Improved:** 96 timesteps (24 hours)

**Why it helps:**
- Captures daily patterns
- Better context for predictions
- Improves long-term forecasts

**Expected improvement:** +10-15% for 12h-24h horizons

---

### 5. **Add More Features** ‚≠ê‚≠ê‚≠ê (Medium Impact)

**Current features:** 97
- Lag features (48)
- Rolling statistics (48)
- Trend features (8)
- Time features (5)

**Additional features to add:**

#### A. Satellite-specific features:
```python
# Add to feature_engineering.py
df['satellite_elevation'] = ...  # Elevation angle
df['satellite_azimuth'] = ...    # Azimuth angle
df['signal_strength'] = ...      # Signal quality
df['geometric_dilution'] = ...   # GDOP
```

#### B. Fourier features (capture periodicity):
```python
from scipy.fft import fft

def add_fourier_features(df, n_components=5):
    for col in ERROR_COLUMNS:
        fft_vals = fft(df[col].values)
        for i in range(1, n_components+1):
            df[f'{col}_fft_real_{i}'] = np.real(fft_vals[i])
            df[f'{col}_fft_imag_{i}'] = np.imag(fft_vals[i])
    return df
```

#### C. Weather features (if available):
```python
df['temperature'] = ...
df['humidity'] = ...
df['atmospheric_pressure'] = ...
```

**Expected improvement:** +5-10% accuracy

---

### 6. **Cross-Validation** ‚≠ê‚≠ê‚≠ê (Medium Impact)

**Current:** Single train/val split  
**Improved:** Time-series cross-validation

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, val_idx in tscv.split(X):
    # Train model on each fold
    # Average predictions
```

**Why it helps:**
- More robust evaluation
- Better hyperparameter tuning
- Reduces variance

**Expected improvement:** +5-8% accuracy

---

### 7. **Ensemble More Models** ‚≠ê‚≠ê‚≠ê (Medium Impact)

**Current ensemble:** LightGBM + LSTM (60/40)

**Add more models:**

#### A. XGBoost:
```python
import xgboost as xgb

model = xgb.XGBRegressor(
    n_estimators=1000,
    learning_rate=0.03,
    max_depth=8,
    subsample=0.8
)
```

#### B. CatBoost:
```python
from catboost import CatBoostRegressor

model = CatBoostRegressor(
    iterations=1000,
    learning_rate=0.03,
    depth=8
)
```

#### C. Transformer model:
```python
# Use attention mechanism for time series
from torch.nn import Transformer
```

**Final ensemble:**
```python
final_pred = (
    0.35 * lightgbm_pred +
    0.25 * xgboost_pred +
    0.20 * catboost_pred +
    0.20 * lstm_pred
)
```

**Expected improvement:** +8-12% accuracy

---

### 8. **Feature Selection** ‚≠ê‚≠ê‚≠ê (Medium Impact)

**Problem:** Not all 97 features are useful

**Solution:** Select most important features

```python
# Get feature importance from LightGBM
importance = model.feature_importance(importance_type='gain')
feature_names = model.feature_name()

# Keep top 60 features
top_features = sorted(zip(feature_names, importance), 
                     key=lambda x: x[1], reverse=True)[:60]

# Retrain with selected features
X_train_selected = X_train[:, top_feature_indices]
```

**Why it helps:**
- Removes noise
- Faster training
- Better generalization

**Expected improvement:** +3-5% accuracy

---

### 9. **Data Augmentation** ‚≠ê‚≠ê (Low-Medium Impact)

**Techniques:**

#### A. Add Gaussian noise:
```python
def augment_data(X, y, noise_level=0.01):
    X_aug = X + np.random.normal(0, noise_level, X.shape)
    return np.vstack([X, X_aug]), np.vstack([y, y])
```

#### B. Time warping:
```python
def time_warp(sequence, sigma=0.2):
    # Slightly stretch/compress time series
    ...
```

#### C. Magnitude warping:
```python
def magnitude_warp(sequence, sigma=0.2):
    # Scale amplitude slightly
    ...
```

**Expected improvement:** +3-5% accuracy

---

### 10. **Post-Processing** ‚≠ê‚≠ê (Low-Medium Impact)

**Techniques:**

#### A. Kalman filtering:
```python
from pykalman import KalmanFilter

kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)
predictions_smoothed = kf.smooth(predictions)[0]
```

#### B. Moving average smoothing:
```python
def smooth_predictions(preds, window=3):
    return np.convolve(preds, np.ones(window)/window, mode='same')
```

#### C. Constraint enforcement:
```python
# Ensure physical constraints
predictions = np.clip(predictions, min_error, max_error)
```

**Expected improvement:** +2-5% accuracy

---

## üìä Implementation Priority

### Phase 1: Quick Wins (1-2 hours)
1. ‚úÖ Run `train_models_improved.py` (already created)
2. ‚úÖ Use early stopping
3. ‚úÖ Increase lookback window

**Expected total improvement:** +25-35%

### Phase 2: Data Collection (1-2 days)
4. Collect more training data (2+ weeks)
5. Add satellite-specific features

**Expected total improvement:** +35-45%

### Phase 3: Advanced Methods (2-3 days)
6. Implement cross-validation
7. Add more ensemble models (XGBoost, CatBoost)
8. Feature selection

**Expected total improvement:** +45-60%

### Phase 4: Fine-tuning (1-2 days)
9. Data augmentation
10. Post-processing with Kalman filter

**Expected total improvement:** +50-70%

---

## üéØ Expected Final Accuracy

### After All Improvements:

| Horizon | Current RMSE | Target RMSE | Improvement |
|---------|--------------|-------------|-------------|
| 15min   | 0.07m        | **0.04m**   | 43% better  |
| 30min   | 0.12m        | **0.07m**   | 42% better  |
| 1h      | 0.15m        | **0.09m**   | 40% better  |
| 3h      | 0.40m        | **0.20m**   | 50% better  |
| 6h      | 0.50m        | **0.25m**   | 50% better  |
| 12h     | 0.80m        | **0.35m**   | 56% better  |
| 24h     | 0.75m        | **0.40m**   | 47% better  |

---

## üöÄ Quick Start: Run Improved Training

```bash
# Step 1: Run improved training script
python train_models_improved.py

# Step 2: Update prediction script to use improved models
# Edit predict_day8.py:
# Change: LIGHTGBM_MODELS_DIR = Path("models/lightgbm")
# To:     LIGHTGBM_MODELS_DIR = Path("models/lightgbm_improved")

# Step 3: Generate predictions
python predict_day8.py

# Step 4: Compare results
# Check: models/metrics_improved/ vs models/metrics/
```

---

## üìà Monitoring Improvements

### Track these metrics:

```python
# 1. Validation RMSE (lower is better)
val_rmse_before = 0.50
val_rmse_after = 0.30
improvement = (val_rmse_before - val_rmse_after) / val_rmse_before * 100
print(f"Improvement: {improvement:.1f}%")

# 2. Overfitting gap (should be small)
gap = train_rmse - val_rmse
print(f"Overfitting gap: {gap:.4f}m")

# 3. Prediction stability (variance across horizons)
std_dev = np.std([rmse_15min, rmse_30min, rmse_1h])
print(f"Prediction stability: {std_dev:.4f}")
```

---

## üîß Troubleshooting

### If accuracy doesn't improve:

1. **Check data quality:**
   - Remove outliers more aggressively
   - Check for missing values
   - Verify time alignment

2. **Verify feature engineering:**
   - Plot feature distributions
   - Check for feature correlations
   - Remove redundant features

3. **Tune hyperparameters:**
   - Use grid search or Bayesian optimization
   - Try different learning rates
   - Adjust regularization strength

4. **Analyze errors:**
   - Plot prediction errors by time of day
   - Check errors by satellite position
   - Identify systematic biases

---

## üìö Additional Resources

### Papers on GNSS Error Prediction:
1. "Deep Learning for GNSS Error Prediction" (2022)
2. "Ensemble Methods for Satellite Navigation" (2021)
3. "Time Series Forecasting with Transformers" (2023)

### Useful Libraries:
- **sktime**: Time series ML toolkit
- **tslearn**: Time series clustering
- **prophet**: Facebook's forecasting tool
- **darts**: Time series forecasting library

---

## ‚úÖ Summary

**Easiest improvements (do first):**
1. ‚úÖ Run `train_models_improved.py`
2. ‚úÖ Collect more data (2+ weeks)
3. ‚úÖ Use early stopping

**Expected improvement:** +35-45% accuracy

**Best long-term strategy:**
- Continuous data collection
- Regular model retraining
- Ensemble multiple models
- Monitor performance metrics

Good luck improving your model! üöÄ
